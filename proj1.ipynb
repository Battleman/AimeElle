{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss_LMSE(y, tx, w):\n",
    "    ## MSE cost function \n",
    "    N = y.shape(0)\n",
    "    e = y - tx.dot(w)\n",
    "    loss = 1/(2*N)*dot(e.T,e)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient_LMSE(y, tx, w):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    N = y.shape[0]\n",
    "    e = y - tx.dot(w)\n",
    "    grad = -1\n",
    "    return grad, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stochastic gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient from just few examples n and their corresponding y_n labels.\"\"\"\n",
    "    err = y - tx.dot(w)\n",
    "    grad = -tx.T.dot(err) / len(err)\n",
    "    return grad, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_function(value):\n",
    "    \"\"\"compute the sigmoid function : 1/(1+np.exp(-value))\"\"\"\n",
    "return 1/(1+np.exp(-value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient_logistic(y, tx, w):\n",
    "    \"\"\"compute the gradient for logistic regression.\"\"\"\n",
    "    y[y==-1] = 0\n",
    "    grad = tx.T.dot(logistic_function(tx.dot(w)) - y)\n",
    "return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les fonctions demand√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"calculate the least squares solution.\"\"\"\n",
    "    a = tx.T.dot(tx)\n",
    "    b = tx.T.dot(y)\n",
    "    w = np.linalg.solve(a,b)\n",
    "    return w, compute_loss_LMSE(y,tx,w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    aI = 2 * tx.shape[0] * lambda_ * np.identity(tx.shape[1])\n",
    "    a = tx.T.dot(tx) + aI\n",
    "    b = tx.T.dot(y)\n",
    "    w = np.linalg.solve(a,b)\n",
    "    return w, compute_loss_LMSE(y,tx,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        grad, err = compute_gradient_LMSE(y, tx, w)\n",
    "        w = w - gamma * grad   \n",
    "    return w, compute_loss_LMSE(y,tx,w)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_SGD(y, tx, initial_w, max_iters, gamma):\n",
    "    batch_size = 1\n",
    "    w = initinal_w\n",
    "    for n_iter in range(max_iters):\n",
    "        for y_batch, tx_batch in batch_iter(y, tx, batch_size = batch_size, num_batches =1):\n",
    "            grad, _ = compute_stoch_gradient(y_batch, tx_batch, w)\n",
    "            w = w - gamma * grad\n",
    "    return w, compute_loss_LMSE(y,tx,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(y, tx, initial w, max_iters, gamma):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_ , initial_w, max_iters, gamma):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
