{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as spstats\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_measures = 'data/IMPROVE_2015_measures_cs433.csv'\n",
    "filename_spectra = 'data/IMPROVE_2015_raw_spectra_cs433.csv'\n",
    "filename_tts = 'data/IMPROVE_2015_train_test_split_cs433.csv'\n",
    "# filename_sec_deriv = 'data/IMPROVE_2015_2nd-derivative_spectra_cs433.csv'\n",
    "\n",
    "df_spectra_raw = pd.read_csv(filename_spectra)\n",
    "df_measures_raw = pd.read_csv(filename_measures)\n",
    "df_train_test_split_raw = pd.read_csv(filename_tts)\n",
    "# df_second_derivative = pd.read_csv(filename_sec_deriv, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = ['SiteCode','Date','flag','Latitude','Longitude','DUSTf:Unc']\n",
    "y_col = ['DUSTf:Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_measures = df_measures_raw.set_index('site')\n",
    "df_measures = df_measures[meta_cols + y_col]\n",
    "df_measures.index = pd.Index(df_measures.index, name=\"\")\n",
    "df_measures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spectra = df_spectra_raw.T\n",
    "df_spectra.columns = pd.Float64Index(df_spectra.loc['wavenumber',:], name=\"\")\n",
    "df_spectra = df_spectra.drop('wavenumber')\n",
    "df_spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df_spectra, df_measures, left_index=True, right_index=True)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this merging has as incident effect to ensure only data with measures and vice-versa are kept. This removes unwanted rows (about 2k measure rows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the original dataframes are not useful anymore. Indeed, everything is contained in the `merged` dataframe. We can safely delete the former ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel df_measures\n",
    "%xdel df_measures_raw\n",
    "%xdel df_spectra\n",
    "%xdel df_spectra_raw\n",
    "gc.collect()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged['DUSTf:Value'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7 NaN values in the dust values. We remove them as they are totally useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_indices = merged['DUSTf:Value'].index[merged['DUSTf:Value'].apply(np.isnan)]\n",
    "nan_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.drop(nan_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/train separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train_test_split_raw[df_train_test_split_raw.usage == \"calibration\"].site\n",
    "test = df_train_test_split_raw[df_train_test_split_raw.usage == \"test\"].site\n",
    "merged_train = merged.loc[np.isin(merged.index, train)]\n",
    "merged_test = merged.loc[np.isin(merged.index, test)]\n",
    "%xdel merged\n",
    "%xdel train\n",
    "%xdel test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X,y creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_train.loc[:, [x for x in merged_train.columns if x not in y_col and x not in meta_cols]]\n",
    "y = merged_train[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, f_classif, f_regression, SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = SelectKBest(score_func=f_regression, k=30)\n",
    "test.fit(X,np.ravel(y))\n",
    "selected_cols = X.columns[test.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "new_features = pd.DataFrame(pf.fit_transform(X[selected_cols]), index=X.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_features.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[X.columns[~np.isin(X.columns, selected_cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X[X.columns[~np.isin(X.columns, selected_cols)]], new_features], axis=1)\n",
    "%xdel new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "# ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "# sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can use `X` as the data matrix and `y` as the validation vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
